# Elasticsearch工作原理
## 关于搜索引擎
搜索程序一般由索引链及搜索组件组成。

索引链功能的实现需要按照几个独立的步骤依次完成：
- 检索原始内容
- 根据原始内容来创建对应的文档 
- 对创建的文档进行索引

搜索组件用于接收用户的查询请求并返回相应结果，一般由以下部分组成:
- 用户接口
- 构建可编程查询语句的方法
- 查询语句执行引擎
- 结果展示组件

![](http://attachbak.dataguru.cn/attachments/portal/201512/08/152451jwem10kzsv10erke.png)

著名的开源程序Lucene是为索引组件，它提供了搜索程序的核心索引和搜索模块，例如图中的“Index”及下面的部分；
而ElasticSearch则更像一款搜索组件，它利用Lucene进行文档索引，并向用户提供搜索组件，例如“Index”上面的部分。
二者结合起来组成了一个完整的搜索引擎。

### 索引组件
索引是一种数据结构，它允许对存储在其中的单词进行快速随机访问。当需要从大量文本中快速检索文本目标时，
必须首先将文本内容转换成能够进行快速搜索的格式，以建立针对文本的索引数据结构，此即为索引过程。
它通常由逻辑上互不相关的几个步骤组成:
#### 1. 获取内容
过网络爬虫或蜘蛛程序等来搜集及界定需要索引的内容。Lucene并不提供任何获取内容的组件，因此，
需要由其它应用程序负责完成这一功能，例如著名的开源爬虫程序Solr、Nutch、Grub及Aperture等。
必要时，还可以自行开发相关程序以高效获取自有的特定环境中的数据。获取到的内容需要建立为小数据块，即文档(Document)。
#### 2. 建立文档
获取的原始内容需要转换成专用部件(文档)才能供搜索引擎使用。  一般来说，一个网页、一个PDF文档、一封邮件或一条日志信息可以作为一个文档。文档由带“值(Value)”的“域(Field)”组成，
例如标题(Title)、正文(body)、摘要(abstract)、作者(Author)和链接(url)等。不过，二进制格式的文档处理起来要麻烦一些，例如PDF文件。
#### 3. 文档分析
搜索引擎不能直接对文本进行索引，确切地说，必须首先将文本分割成一系列被称为语汇单元(token)的独立原子元素，此过程即为文档分析。
每个token大致能与自然语言中的“单词”对应起来，文档分析就是用于确定文档中的文本域如何分割成token序列，此即为切词或分词。  
文档分析中要解决的问题包括如何处理连接一体的各个单词、是否需要语法修正(例如原始内容存在错别字)、
是否需要向原始token中插入同义词(例如laptop和notebook)、是否需要将大写字符统一转换为小写字符，
以及是否将单数和复数格式的单词合并成同一个token等。这通常需要词干分析器等来完成此类工作，Lucene提供了大量内嵌的分析器，
也支持用户自定义分析器，甚至联合Lucene的token工具和过滤器创建自定义的分析链。 
#### 4.文档索引
在索引步骤中，文档将被加入到索引列表。事实上，Lucene为此仅提供了一个非常简单的API，而后自行内生地完成了此步骤的所有功能。

### 搜索组件
索引处理就是从索引中查找单词，从而找到包含该单词的文档的过程。搜索质量主要由查准率(Precision)和查全率(Recall)两个指标进行衡量。
查准率用来衡量搜索系列过滤非相关文档的能力，而查全率用来衡量搜索系统查找相关文档的能力。  
另外，除了快速搜索大量文本和搜索速度之后，搜索过程还涉及到了许多其它问题，例如单项查询、多项查询、短语查询、通配符查询、结果排序，以及友好的查询输入方式等。
这些问题的解决，通常需要多个组件协作完成。
#### 1. 用户搜索界面
UI(User Interface)是搜索引擎的重要组成部分，用户通过搜索引擎界面进行搜索交互时，他们会提交一个搜索请求，该请求需要先转换成合适的查询对象格式，以便搜索引擎能执行查询。
#### 2. 建立查询
户提交的搜索请求通常以HTML表单或Ajax请求的形式由浏览器提交到搜索引擎服务器，因此，需要事先由查询解析器一类的组件将这个请求转换成搜索引擎使用的查询对象格式。
#### 3. 搜索查询
 当查询请求建立完成后，就需要查询检索索引并返回与查询语句匹配的并根据请求排好序的文档。搜索查询组件有着复杂的工作机制，它们通常根据搜索理论模型执行查询操作。常见的搜索理论模型有纯布尔模型、向量空间模型及概率模型三种。Lucene采用了向量空间模型和纯布尔模型。
 #### 4. 展现结果
 查询获得匹配查询语句并排好序的文档结果集后，需要用直观、经济的方式为用户展现结果。UI也需要为后续的搜索或操作提供清晰的向导，如完善搜索结果、寻找与匹配结果相似的文档、进入下一页面等。
 
 ## Lucene
 Lucene是一款高性能的、可扩展的信息检索（IR）工具库，是由Java语言开发的成熟、自由开源的搜索类库，基于Apache协议授权。Lucene只是一个软件类库，如果要发挥Lucene的功能，还需要开发一个调用Lucene类库的应用程序。  
 
 文档是Lucene索引和搜索的原子单位，它是包含了一个或多个域的容器，而域的值则是真正被搜索的内容。每个域都有其标识名称，通常为一个文本值或二进制值。
 将文档加入索引中时，需要首先将数据转换成Lucene能识别的文档和域，域值是被搜索的对象。例如，用户输入搜索内容“title:elasticsearch”时，则表示搜索“标题”域值中包含单词“elasticsearch”的所有文档。
 
 ![](http://attachbak.dataguru.cn/attachments/portal/201512/08/152451o196a1pw7ffb9798.png)
 
 如前所述，ElasticSearch在底层利用Lucene完成其索引功能，因此其许多基本概念源于Lucene。
 
 ## Elasticsearch的四种查询类型和搜索原理
 Elasticsearch Client发送搜索请求，搜索某个索引库，一般默认是5个分片（shard），  
返回的时候，由各个分片汇总结果回来。
![](https://images2015.cnblogs.com/blog/855959/201707/855959-20170705222926456-1485587310.png)
### ES 在查询时， 可以指定搜索类型为下面四种：
1. QUERY_AND_FEATCH
2. QUERY_THEN_FETCH
3. DFS_QUERY_AND_FEATCH
4. DFS_QUERY_THEN_FEATCH

那么这 4 种搜索类型有什么区别？  
在讲这四种搜索类型的区别之前， 先分析一下分布式搜索背景介绍：  
ES 天生就是为分布式而生， 但分布式有分布式的缺点。 比如要搜索某个单词， 但是数据却分别在 5 个分片（Shard)上面， 这 5 个分片可能在 5 台主机上面。  
因为全文搜索天生就要排序（ 按照匹配度进行排名） ,但数据却在 5 个分片上， 如何得到最后正确的排序呢？ ES是这样做的， 大概分两步：  
step1： ES 客户端将会同时向 5 个分片发起搜索请求。  
step2： 这 5 个分片基于本分片的内容独立完成搜索， 然后将符合条件的结果全部返回。  
客户端将返回的结果进行重新排序和排名，最后返回给用户。也就是说，ES的一次搜索，是一次scatter/gather过程（这个跟mapreduce也很类似）

#### 然而这其中有两个问题：
第一、 数量问题。 比如， 用户需要搜索"衣服"， 要求返回符合条件的前 10 条。 但在 5个分片中， 可能都存储着衣服相关的数据。 所以 ES 会向这 5 个分片都发出查询请求， 并且要求每个分片都返回符合条件的 10 条记录。当ES得到返回的结果后，进行整体排序，然后取最符合条件的前10条返给用户。 这种情况， ES 中 5 个 shard 最多会收到 10*5=50条记录， 这样返回给用户的结果数量会多于用户请求的数量。

第二、 排名问题。 上面说的搜索， 每个分片计算符合条件的前 10 条数据都是基于自己分片的数据进行打分计算的。计算分值使用的词频和文档频率等信息都是基于自己分片的数据进行的， 而 ES 进行整体排名是基于每个分片计算后的分值进行排序的(相当于打分依据就不一样， 最终对这些数据统一排名的时候就不准确了)， 这就可能会导致排名不准确的问题。如果我们想更精确的控制排序， 应该先将计算排序和排名相关的信息（ 词频和文档频率等打分依据） 从 5 个分片收集上来， 进行统一计算， 然后使用整体的词频和文档频率为每个分片中的数据进行打分， 这样打分依据就一样了。

#### Elasticsearch对这两个搜索问题的解决思路
1.返回数据数量问题  
第一步：先从每个分片汇总查询的数据id和分数，进行排名，取前10条数据  
第二步：根据这10条数据id，到不同分片获取数据  
（2）返回数据排名问题  
将各个分片打分标准统一  
### Elasticsearch的搜索类型（SearchType类型）
#### 1、 query and fetch
向索引的所有分片 （ shard）都发出查询请求， 各分片返回的时候把元素文档 （ document）和计算后的排名信息一起返回。
  
这种搜索方式是最快的。 因为相比下面的几种搜索方式， 这种查询方法只需要去 shard查询一次。 但是各个 shard 返回的结果的数量之和可能是用户要求的 size 的 n 倍。
  
优点：这种搜索方式是最快的。因为相比后面的几种es的搜索方式，这种查询方法只需要去shard查询一次。  
缺点：返回的数据量不准确， 可能返回(N*分片数量)的数据并且数据排名也不准确，同时各个shard返回的结果的数量之和可能是用户要求的size的n倍。

#### 2、 query then fetch（ es 默认的搜索方式）
如果你搜索时， 没有指定搜索方式， 就是使用的这种搜索方式。 这种搜索方式， 大概分两个步骤：  
第一步， 先向所有的 shard 发出请求， 各分片只返回文档 id(注意， 不包括文档 document)和排名相关的信息(也就是文档对应的分值)， 然后按照各分片返回的文档的分数进行重新排序和排名， 取前 size 个文档。  
第二步， 根据文档 id 去相关的 shard 取 document。 这种方式返回的 document 数量与用户要求的大小是相等的。

优点：返回的数据量是准确的。  
缺点：性能一般，并且数据排名不准确。

#### 3、 DFS query and fetch
这种方式比第 1 种方式多了一个 DFS 步骤，有这一步，可以更精确控制搜索打分和排名。也就是在进行查询之前， 先对所有分片发送请求， 把所有分片中的词频和文档频率等打分依据全部汇总到一块， 再执行后面的操作。
  
优点：数据排名准确  
缺点：性能一般，返回的数据量不准确， 可能返回(N*分片数量)的数据

#### DFS query then fetch
比第 2 种方式多了一个 DFS 步骤。  
也就是在进行查询之前， 先对所有分片发送请求， 把所有分片中的词频和文档频率等打分依据全部汇总到一块， 再执行后面的操作。

优点：返回的数据量是准确的，数据排名准确
缺点：性能最差【 这个最差只是表示在这四种查询方式中性能最慢， 也不至于不能忍受，如果对查询性能要求不是非常高， 而对查询准确度要求比较高的时候可以考虑这个】

#### DFS 是一个什么样的过程？
从 es 的官方网站我们可以发现， DFS 其实就是在进行真正的查询之前， 先把各个分片的词频率和文档频率收集一下， 然后进行词搜索的时候， 各分片依据全局的词频率和文档频率进行搜索和排名。 显然如果使用 DFS_QUERY_THEN_FETCH 这种查询方式， 效率是最低的，因为一个搜索， 可能要请求 3 次分片。 但， 使用 DFS 方法， 搜索精度是最高的。  

总结一下， 从性能考虑 QUERY_AND_FETCH 是最快的， DFS_QUERY_THEN_FETCH 是最慢的。从搜索的准确度来说， DFS 要比非 DFS 的准确度更高。  